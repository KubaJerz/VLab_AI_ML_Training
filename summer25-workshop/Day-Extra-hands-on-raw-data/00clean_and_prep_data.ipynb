{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "71e2a592",
   "metadata": {},
   "source": [
    "## 1 \n",
    "\n",
    "Import the librarys we need.\n",
    "\n",
    "- We know our file is a .CSV so lets import `pandas`\n",
    "- I will also import a few more libraries I expect to use. If they are not clear, don't import them, and you can go back and add them when it becomes clear that we will need them\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223616d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b098ef8",
   "metadata": {},
   "source": [
    "Import data and look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f50df8b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('breast_cancer_dataset_raw_manipulated.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c204b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da7ce6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "340f1899",
   "metadata": {},
   "source": [
    " We can't see all the columns so lets get the title of each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4c24731",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b74c5309",
   "metadata": {},
   "source": [
    "## 2\n",
    "\n",
    "Lets note some observations.\n",
    "\n",
    "- `Unnamed` seems to be a duplicate of the index column\n",
    "- For the `README.txt` we know the `id` column is not going to help us in classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00b5dd3c",
   "metadata": {},
   "source": [
    "Lets keep looking around and check the `diagnosis` column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5edd4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb9b4ed",
   "metadata": {},
   "source": [
    "Lets get the count of each \"class\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed3ff011",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts = []\n",
    "for diagnosis_type in df['diagnosis'].unique():\n",
    "    count = (df['diagnosis'] == diagnosis_type).sum()\n",
    "    counts.append(count.item())\n",
    "    print(f\"{diagnosis_type} has {count} occurrence\")\n",
    "\n",
    "print(f\"\\nTotal counts is: {sum(counts)}\")\n",
    "print(f\"df is of size: {len(df)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca61a1f",
   "metadata": {},
   "source": [
    "Interesting let's look into the `nan` and figure out why we are not counting it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f617de51",
   "metadata": {},
   "outputs": [],
   "source": [
    "for diagnosis_type in df['diagnosis'].unique():\n",
    "    print(f\"{diagnosis_type} is of type: {type(diagnosis_type)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf6d21e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "type(np.nan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4068fe",
   "metadata": {},
   "source": [
    "Lets see if the base case checks out."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d077ed5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.nan == np.nan"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56c950c7",
   "metadata": {},
   "source": [
    "\n",
    "This makes sense now.\n",
    "\n",
    "We don't catch `np.nan` in the for loop above because `np.nan != np.nan`, so `df['diagnosis'] == np.nan` is always `False`.\n",
    "\n",
    "`np.nan != np.nan` because NaN (Not a Number) is defined to be unequal to everything, including itself.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80be123",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"We are missing: {len(df) - sum(counts)} values. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3ef54fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['diagnosis'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1520818",
   "metadata": {},
   "source": [
    "\n",
    "When me make out classification datset we can't have rows that don't have a class so we must drop these rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f0a8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[ ~df['diagnosis'].isna()]\n",
    "len(df), df['diagnosis'].isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68bbb4ea",
   "metadata": {},
   "source": [
    "# 3\n",
    "\n",
    "Since `Unnamed` is treated like another feature insted of the index that it is lets go ahead and drop it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f87b697",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9ef42f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.drop(columns=['Unnamed: 0'])\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e06772eb",
   "metadata": {},
   "source": [
    "## 4\n",
    "\n",
    "Lets check for duplicate rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ba1c346",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1042fdbe",
   "metadata": {},
   "source": [
    "This is where you ask yourself the question that is specific for your dataset.\n",
    "- *\"Does having duplicates make sense in my context\"*\n",
    "\n",
    "For us duplicates don't make sense so we will drop them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd2b13",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6d1f55d",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b52907bd",
   "metadata": {},
   "source": [
    "## 5\n",
    "\n",
    "Lets check for missing data:\n",
    "- Check across rows.\n",
    "\n",
    "- Check across columns.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ea88176",
   "metadata": {},
   "source": [
    "**5.1** Check across rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec565539",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"column id : # missing rows\\n\")\n",
    "for col in df.columns:\n",
    "    print(f\"{col} : {df[col].isnull().sum()}\")\n",
    "    # print(\"-\"* 50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0208c7cf",
   "metadata": {},
   "source": [
    "**5.2** Check across column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f38fbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "(df.isnull().sum(axis=1) > 0).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75fe21f4",
   "metadata": {},
   "source": [
    "Looks to be 54 rows that contain a NaN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eac5565",
   "metadata": {},
   "source": [
    "There are many ways to deal with missing data:\n",
    "-  Fill with a Mean/Median\n",
    "-  Forward Fill (`ffill`): Replacing NaN values with the previous non-NaN value in the same column\n",
    "-  Backward Fill (`bfill`): Replacing NaN values with the next non-NaN value in the same column\n",
    "-  Droping the rows\n",
    "\n",
    "\n",
    "We will opt for dropping the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1889c9a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.dropna(axis=0)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6be4c98",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83b458f0",
   "metadata": {},
   "source": [
    "## 6\n",
    "\n",
    "Lets check the data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24ac4f65",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6cd23e",
   "metadata": {},
   "source": [
    "Thoses look good"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f52add",
   "metadata": {},
   "source": [
    "## 7\n",
    "Great now that out data is clean lets make the `X`, `y`\n",
    "\n",
    "1. We dont need `id` in `X`\n",
    "2. We need `y` to be 0/1 not \"benign\"/\"malignant\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc1924cc",
   "metadata": {},
   "source": [
    "**7.1**\n",
    "\n",
    "Make the `X` matrix:\n",
    "\n",
    "- Drop `[id, diagnosis]`\n",
    "\n",
    "- Turn into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2ecee95",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df.drop(columns=['id', 'diagnosis']).to_numpy()\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a800910",
   "metadata": {},
   "source": [
    "**7.2** \n",
    "\n",
    "Make the `y` vector:\n",
    "- Use just column `diagnosis`\n",
    "\n",
    "- Convert to be 0 or 1\n",
    "\n",
    "- Turn into numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9c956ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = df['diagnosis'].apply(lambda x: 0 if x == 'benign' else 1).to_numpy()\n",
    "# y = np.where(df['diagnosis'] == 'benign', 0, 1).to_numpy()\n",
    "y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87e2a2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape of X: {X.shape}  and shape of y: {y.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f571fa16",
   "metadata": {},
   "source": [
    "**7.3** \n",
    "\n",
    "Split them up 80/20  for Train/Test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5f174e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#shuffle the data first\n",
    "np.random.seed(42) # for reproducibility\n",
    "perm_idxs = np.random.permutation(len(X))\n",
    "X = X[perm_idxs]\n",
    "y = y[perm_idxs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3673597",
   "metadata": {},
   "outputs": [],
   "source": [
    "#split them \n",
    "train_size = int(len(X) * 0.8 )\n",
    "X_train, y_train = X[:train_size], y[:train_size]\n",
    "X_test, y_test = X[train_size:], y[train_size:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d29e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Shape X train: {X_train.shape}  Shape y train: {y_train.shape}\")\n",
    "print(f\"Shape X test: {X_test.shape}  Shape y test: {y_test.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7107c07",
   "metadata": {},
   "source": [
    "**7.4**\n",
    "\n",
    "We now save our processed data to be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6def14f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('X_train.npy', X_train)\n",
    "np.save('y_train.npy', y_train)\n",
    "\n",
    "np.save('X_test.npy', X_test)\n",
    "np.save('y_test.npy', y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07f3e0e3",
   "metadata": {},
   "source": [
    "or we save them as `.pt`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff17b66d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.save(X_train, 'X_train.pt')\n",
    "# torch.save(y_train, 'y_train.pt')\n",
    "\n",
    "# torch.save(X_test, 'X_test.pt')\n",
    "# torch.save(y_test, 'y_test.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
